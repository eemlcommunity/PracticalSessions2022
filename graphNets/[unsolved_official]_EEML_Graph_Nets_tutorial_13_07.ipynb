{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eemlcommunity/PracticalSessions2022/blob/main/graphNets/%5Bunsolved_official%5D_EEML_Graph_Nets_tutorial_13_07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAsDW2v2yPNE"
      },
      "source": [
        "# Dynamics modelling using MPNNs\n",
        "\n",
        "\n",
        "**Authors:** [Iulia Du»õƒÉ](https://iuliaduta.github.io/) and [CƒÉtƒÉlina Cangea](https://catalinacangea.netlify.app/)\n",
        "\n",
        "**Abstract:** This tutorial covers basic concepts from the field of Graph Representation Learning, such as:\n",
        "* representing a graph structure in an ML setup;\n",
        "* implementing Graph Neural Network (GNN) variants: [Graph Convolutional Network](https://arxiv.org/abs/1609.02907) (GCN), [Message Passing Neural Network](https://arxiv.org/pdf/1704.01212v2.pdf) (MPNN);\n",
        "* learning to infer the structure of a graph.\n",
        "\n",
        "**Outline of the tutorial:**\n",
        "1. Create a dataset to simulate the movement of a set of particles.\n",
        "2. Show how to represent graphs in memory.\n",
        "3. Implement a GNN to predict the trajectories of the particles, given the _ground-truth graph connectivity_ (i.e. the edges of the graph).\n",
        "4.  Implement a GNN to predict these trajectories, this time _assuming the graph is fully-connected_ (i.e. each node links to all others).\n",
        "5. Learn to predict the connectivity using an encoder similar to the one used in the NRI ([Neural Relational Inference](https://arxiv.org/abs/1802.04687)) model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n775s3pmKcwK"
      },
      "source": [
        "# üò© **Preliminaries:** Install and import modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTwW_Wokzumn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "!pip install torch-geometric torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4LmlOImKgrR",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title [RUN] Imports\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "import networkx as nx\n",
        "\n",
        "from numpy import linspace\n",
        "import random\n",
        "\n",
        "from matplotlib import cm\n",
        "from matplotlib.lines import Line2D \n",
        "   \n",
        "import scipy.linalg\n",
        "from scipy.linalg import block_diag\n",
        "\n",
        "import pdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uP55p4OpzpF",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title [RUN] Helper functions for plots and visualisations\n",
        "\n",
        "global_train_stats = {}\n",
        "####### Helper functions for plots #######\n",
        "def update_stats(training_stats, epoch_stats):\n",
        "    \"\"\" Store metrics along the training\n",
        "    Args:\n",
        "      epoch_stats: dict containg metrics about one epoch\n",
        "      training_stats: dict containing lists of metrics along training\n",
        "    Returns:\n",
        "      updated training_stats\n",
        "    \"\"\"\n",
        "    if training_stats is None:\n",
        "        training_stats = {}\n",
        "        for key in epoch_stats.keys():\n",
        "            training_stats[key] = []\n",
        "    for key,val in epoch_stats.items():\n",
        "        training_stats[key].append(val)\n",
        "    return training_stats\n",
        "\n",
        "def plot_cumulate_stats(global_training_stats, training_stats, figsize=(5, 5), name=\"\"):\n",
        "    \"\"\" Create one plot for each metric stored in training_stats\n",
        "    \"\"\"\n",
        "    for key,val in training_stats.items():\n",
        "      global_training_stats.update({f'{key}_{name}': val})\n",
        "    stats_names = [key[6:] for key in global_training_stats.keys() if key.startswith('train_')]\n",
        "    f, ax = plt.subplots(len(stats_names), 1, figsize=figsize)\n",
        "    if len(stats_names)==1:\n",
        "        ax = np.array([ax])\n",
        "    for key, axx in zip(stats_names, ax.reshape(-1,)):\n",
        "        axx.plot(\n",
        "            global_training_stats[f'epoch_{name}'],\n",
        "            global_training_stats[f'train_{key}'],\n",
        "            label=f\"Training {key}\")\n",
        "        axx.plot(\n",
        "            global_training_stats[f'epoch_{name}'],\n",
        "            global_training_stats[f'val_{key}'],\n",
        "            label=f\"Validation {key}\")\n",
        "        axx.set_xlabel(\"Training epoch\")\n",
        "        axx.set_ylabel(key)\n",
        "        axx.legend()\n",
        "    plt.title(name)\n",
        "    return global_training_stats\n",
        "    \n",
        "def plot_stats(training_stats, figsize=(5, 5), name=\"\"):\n",
        "    \"\"\" Create one plot for each metric stored in training_stats\n",
        "    \"\"\"\n",
        "    stats_names = [key[6:] for key in training_stats.keys() if key.startswith('train_')]\n",
        "    f, ax = plt.subplots(len(stats_names), 1, figsize=figsize)\n",
        "    if len(stats_names)==1:\n",
        "        ax = np.array([ax])\n",
        "    for key, axx in zip(stats_names, ax.reshape(-1,)):\n",
        "        axx.plot(\n",
        "            training_stats['epoch'],\n",
        "            training_stats[f'train_{key}'],\n",
        "            label=f\"Training {key}\")\n",
        "        axx.plot(\n",
        "            training_stats['epoch'],\n",
        "            training_stats[f'val_{key}'],\n",
        "            label=f\"Validation {key}\")\n",
        "        axx.set_xlabel(\"Training epoch\")\n",
        "        axx.set_ylabel(key)\n",
        "        axx.legend()\n",
        "    plt.title(name)\n",
        "\n",
        "def get_color_coded_str(i, color):\n",
        "    return \"\\033[3{}m{}\\033[0m\".format(int(color), int(i))\n",
        "\n",
        "def print_color_numpy(map, list_graphs):\n",
        "    \"\"\" print matrix map in color according to list_graphs\n",
        "    \"\"\"\n",
        "    list_blocks = []\n",
        "    for i,graph in enumerate(list_graphs):\n",
        "        block_i = (i+1)*np.ones((graph.num_nodes,graph.num_nodes))\n",
        "        list_blocks += [block_i]\n",
        "    block_color = block_diag(*list_blocks)\n",
        "    \n",
        "    map_modified = np.vectorize(get_color_coded_str)(map, block_color)\n",
        "    print(\"\\n\".join([\" \".join([\"{}\"]*map.shape[0])]*map.shape[1]).format(*[x for y in map_modified.tolist() for x in y]))\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2TCR8mIAK8N"
      },
      "source": [
        "# üöÄ **Part 1:** Dataset of simulated particle movements\n",
        "\n",
        "\n",
        "The tutorial focuses on solving a physics-inspired task: simulating the movement of a set of particles connected by strings. There are `n_balls` moving; these may or may not interact with equal probability, which determines the trajectories of the balls.\n",
        "\n",
        "Our goal is to **use an observed part of the trajectory** to **predict what will happen in the future** and **recover the interactions**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYSd1nOjOh3n"
      },
      "source": [
        "<!-- ![image](https://drive.google.com/uc?export=view&id=1pCoFuLCISrbL59DS--KHcwBagANFYjPy){ width=5% } -->\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1pCoFuLCISrbL59DS--KHcwBagANFYjPy\"  width=\"200\" height=\"200\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNlXSTffR3DV"
      },
      "source": [
        "During this tutorial, we will vary the amount of information that we receive about particle interactions, process this information using Graph Neural Networks and analyse how the trajectory prediction is influenced by this choices.\n",
        "\n",
        "In turn, we will:\n",
        "\n",
        "* use the **ground-truth connectivity**;\n",
        "* assume interactions take place between all pairs of particles (**fully-connected interaction graph**);\n",
        "* **predict** the interactions (NRI-like).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pv5JgVCyZsLC"
      },
      "outputs": [],
      "source": [
        "#@title [RUN] A springs trajectory simulator class\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "\n",
        "class SpringSim(object):\n",
        "    def __init__(self, n_balls=5, box_size=5., loc_std=.5, vel_norm=.5,\n",
        "                 interaction_strength=.1, noise_var=0.):\n",
        "        self.n_balls = n_balls\n",
        "        self.box_size = box_size\n",
        "        self.loc_std = loc_std\n",
        "        self.vel_norm = vel_norm\n",
        "        self.interaction_strength = interaction_strength\n",
        "        self.noise_var = noise_var\n",
        "\n",
        "        self._spring_types = np.array([0., 0.5, 1.])\n",
        "        self._delta_T = 0.001\n",
        "        self._max_F = 0.1 / self._delta_T\n",
        "\n",
        "    def _energy(self, loc, vel, edges):\n",
        "        # disables division by zero warning, since I fix it with fill_diagonal\n",
        "        with np.errstate(divide='ignore'):\n",
        "\n",
        "            K = 0.5 * (vel ** 2).sum()\n",
        "            U = 0\n",
        "            for i in range(loc.shape[1]):\n",
        "                for j in range(loc.shape[1]):\n",
        "                    if i != j:\n",
        "                        r = loc[:, i] - loc[:, j]\n",
        "                        dist = np.sqrt((r ** 2).sum())\n",
        "                        U += 0.5 * self.interaction_strength * edges[\n",
        "                            i, j] * (dist ** 2) / 2\n",
        "            return U + K\n",
        "\n",
        "    def _clamp(self, loc, vel):\n",
        "        '''\n",
        "        :param loc: 2xN location at one time stamp\n",
        "        :param vel: 2xN velocity at one time stamp\n",
        "        :return: location and velocity after hiting walls and returning after\n",
        "            elastically colliding with walls\n",
        "        '''\n",
        "        assert (np.all(loc < self.box_size * 3))\n",
        "        assert (np.all(loc > -self.box_size * 3))\n",
        "\n",
        "        over = loc > self.box_size\n",
        "        loc[over] = 2 * self.box_size - loc[over]\n",
        "        assert (np.all(loc <= self.box_size))\n",
        "\n",
        "        # assert(np.all(vel[over]>0))\n",
        "        vel[over] = -np.abs(vel[over])\n",
        "\n",
        "        under = loc < -self.box_size\n",
        "        loc[under] = -2 * self.box_size - loc[under]\n",
        "        # assert (np.all(vel[under] < 0))\n",
        "        assert (np.all(loc >= -self.box_size))\n",
        "        vel[under] = np.abs(vel[under])\n",
        "\n",
        "        return loc, vel\n",
        "\n",
        "    def _l2(self, A, B):\n",
        "        \"\"\"\n",
        "        Input: A is a Nxd matrix\n",
        "               B is a Mxd matirx\n",
        "        Output: dist is a NxM matrix where dist[i,j] is the square norm\n",
        "            between A[i,:] and B[j,:]\n",
        "        i.e. dist[i,j] = ||A[i,:]-B[j,:]||^2\n",
        "        \"\"\"\n",
        "        A_norm = (A ** 2).sum(axis=1).reshape(A.shape[0], 1)\n",
        "        B_norm = (B ** 2).sum(axis=1).reshape(1, B.shape[0])\n",
        "        dist = A_norm + B_norm - 2 * A.dot(B.transpose())\n",
        "        return dist\n",
        "\n",
        "    def sample_trajectory(self, T=10000, sample_freq=10,\n",
        "                          spring_prob=[1. / 2, 0, 1. / 2]):\n",
        "        n = self.n_balls\n",
        "        assert (T % sample_freq == 0)\n",
        "        T_save = int(T / sample_freq - 1)\n",
        "        diag_mask = np.ones((n, n), dtype=bool)\n",
        "        np.fill_diagonal(diag_mask, 0)\n",
        "        counter = 0\n",
        "        # Sample edges\n",
        "        edges = np.random.choice(self._spring_types,\n",
        "                                 size=(self.n_balls, self.n_balls),\n",
        "                                 p=spring_prob)\n",
        "        edges = np.tril(edges) + np.tril(edges, -1).T\n",
        "        np.fill_diagonal(edges, 0)\n",
        "        # Initialize location and velocity\n",
        "        loc = np.zeros((T_save, 2, n))\n",
        "        vel = np.zeros((T_save, 2, n))\n",
        "        loc_next = np.random.randn(2, n) * self.loc_std\n",
        "        vel_next = np.random.randn(2, n)\n",
        "        v_norm = np.sqrt((vel_next ** 2).sum(axis=0)).reshape(1, -1)\n",
        "        vel_next = vel_next * self.vel_norm / v_norm\n",
        "        loc[0, :, :], vel[0, :, :] = self._clamp(loc_next, vel_next)\n",
        "\n",
        "        # disables division by zero warning, since I fix it with fill_diagonal\n",
        "        with np.errstate(divide='ignore'):\n",
        "\n",
        "            forces_size = - self.interaction_strength * edges\n",
        "            np.fill_diagonal(forces_size,\n",
        "                             0)  # self forces are zero (fixes division by zero)\n",
        "            F = (forces_size.reshape(1, n, n) *\n",
        "                 np.concatenate((\n",
        "                     np.subtract.outer(loc_next[0, :],\n",
        "                                       loc_next[0, :]).reshape(1, n, n),\n",
        "                     np.subtract.outer(loc_next[1, :],\n",
        "                                       loc_next[1, :]).reshape(1, n, n)))).sum(\n",
        "                axis=-1)\n",
        "            F[F > self._max_F] = self._max_F\n",
        "            F[F < -self._max_F] = -self._max_F\n",
        "\n",
        "            vel_next += self._delta_T * F\n",
        "            # run leapfrog\n",
        "            for i in range(1, T):\n",
        "                loc_next += self._delta_T * vel_next\n",
        "                loc_next, vel_next = self._clamp(loc_next, vel_next)\n",
        "\n",
        "                if i % sample_freq == 0:\n",
        "                    loc[counter, :, :], vel[counter, :, :] = loc_next, vel_next\n",
        "                    counter += 1\n",
        "\n",
        "                forces_size = - self.interaction_strength * edges\n",
        "                np.fill_diagonal(forces_size, 0)\n",
        "                # assert (np.abs(forces_size[diag_mask]).min() > 1e-10)\n",
        "\n",
        "                F = (forces_size.reshape(1, n, n) *\n",
        "                     np.concatenate((\n",
        "                         np.subtract.outer(loc_next[0, :],\n",
        "                                           loc_next[0, :]).reshape(1, n, n),\n",
        "                         np.subtract.outer(loc_next[1, :],\n",
        "                                           loc_next[1, :]).reshape(1, n,\n",
        "                                                                   n)))).sum(\n",
        "                    axis=-1)\n",
        "                F[F > self._max_F] = self._max_F\n",
        "                F[F < -self._max_F] = -self._max_F\n",
        "                vel_next += self._delta_T * F\n",
        "            # Add noise to observations\n",
        "            loc += np.random.randn(T_save, 2, self.n_balls) * self.noise_var\n",
        "            vel += np.random.randn(T_save, 2, self.n_balls) * self.noise_var\n",
        "            return loc, vel, edges\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L73fLR5jS4T6"
      },
      "source": [
        "Above, we provide the class that implements a particle trajectory simulator. \n",
        "\n",
        "For training, we generate `num_train_sims` trajectories, each one containing `n_balls` objects, observed for a `trajectory_length` seconds, and we record the position (_x,y_ coordinates) after every `sample_every_n_steps` seconds.\n",
        "\n",
        "For validation, we will generate the data similarly, but restricting the generation to only `num_valid_sims` trajectories.\n",
        "\n",
        "For test, we generate `num_test_sims`; here, each trajectory is observed instead for `test_trajectory_length` (which should be at least 2 $\\times$ `trajectory_length`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0NQEbdqUNp1"
      },
      "source": [
        "Let's now generate datasets containing these trajectories. Depending on the parameters, running this code might take some time... ‚è≥‚åõÔ∏è\n",
        "\n",
        "‚ö†Ô∏è NOTE: we have already provided a generated dataset containing 45,000 trajectories for training and 200 validation/test trajectories. In order to use that dataset instead, you should:\n",
        "\n",
        "1. Download the `.pkl` file from `github`.\n",
        "2. Upload the file into your Google Drive.\n",
        "3. Change the file path `save_data_file_name` in the following script to point to the location in your Google Drive where you saved the file.\n",
        "4. Run the script with `load_existing_dataset=True` (running the script will require you to give access rights to your Google Drive account)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dlvyJzOoaeFM"
      },
      "outputs": [],
      "source": [
        "#@title Create a simulated spring trajectory dataset\n",
        "\n",
        "# This flag set to true will disable all the other params\n",
        "# and load the existing dataset stored in path instead\n",
        "load_existing_dataset = True#@param {type:\"boolean\"}\n",
        "save_data_file_name = '/content/gdrive/MyDrive/'+ f'dataset_combined.pkl'\n",
        "\n",
        "# Parameters for generating the dataset\n",
        "n_balls = 4 #@param {type:\"integer\"}\n",
        "num_train_sims =  1000#@param {type:\"integer\"}\n",
        "num_valid_sims =  200#@param {type:\"integer\"}\n",
        "num_test_sims =  200#@param {type:\"integer\"}\n",
        "trajectory_length = 5000 #@param {type:\"integer\"}\n",
        "test_trajectory_length = 10000 #@param {type:\"integer\"}\n",
        "sample_every_n_steps = 100 #@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "assert trajectory_length % sample_every_n_steps == 0, \\\n",
        "    \"`trajectory_length` needs to be divisible by `sample_every_n_steps`\"\n",
        "assert test_trajectory_length % sample_every_n_steps == 0, \\\n",
        "    \"`test_trajectory_length` needs to be divisible by `sample_every_n_steps`\"\n",
        "\n",
        "sim = SpringSim(noise_var=0.0, n_balls=n_balls)\n",
        "\n",
        "def generate_dataset(num_sims, length, sample_freq):\n",
        "    loc_all = list()\n",
        "    vel_all = list()\n",
        "    edges_all = list()\n",
        "\n",
        "    for i in range(num_sims):\n",
        "        t = time.time()\n",
        "        loc, vel, edges = sim.sample_trajectory(T=length,\n",
        "                                                sample_freq=sample_freq)\n",
        "        if i % 100 == 0:\n",
        "            print(\"Iter: {}, Simulation time: {}\".format(i, time.time() - t))\n",
        "        loc_all.append(loc)\n",
        "        vel_all.append(vel)\n",
        "        edges_all.append(edges)\n",
        "\n",
        "    loc_all = np.stack(loc_all)\n",
        "    vel_all = np.stack(vel_all)\n",
        "    edges_all = np.stack(edges_all)\n",
        "\n",
        "    return loc_all, vel_all, edges_all\n",
        "\n",
        "if load_existing_dataset == False:\n",
        "    print(\"Generating {} training simulations\".format(num_train_sims))\n",
        "    loc_train, vel_train, edges_train = generate_dataset(num_train_sims,\n",
        "                                                        trajectory_length,\n",
        "                                                        sample_every_n_steps)\n",
        "\n",
        "    print(\"Generating {} validation simulations\".format(num_valid_sims))\n",
        "    loc_valid, vel_valid, edges_valid = generate_dataset(num_valid_sims,\n",
        "                                                        trajectory_length,\n",
        "                                                        sample_every_n_steps)\n",
        "\n",
        "    print(\"Generating {} test simulations\".format(num_test_sims))\n",
        "    loc_test, vel_test, edges_test = generate_dataset(num_test_sims,\n",
        "                                                      test_trajectory_length,\n",
        "                                                      sample_every_n_steps)\n",
        "\n",
        "    for (loc, vel, edges, num_sims) in [\n",
        "        (loc_train, vel_train, edges_train, num_train_sims),\n",
        "        (loc_valid, vel_valid, edges_valid, num_valid_sims),\n",
        "        (loc_test, vel_test, edges_test, num_test_sims),\n",
        "    ]:\n",
        "      ls = loc.shape\n",
        "      assert (ls[0] == num_sims and\n",
        "              ls[1] == trajectory_length // sample_every_n_steps - 1 and\n",
        "              ls[-1] == n_balls)\n",
        "      vs = vel.shape\n",
        "      assert ls == vs\n",
        "      es = edges.shape\n",
        "      assert es[0] == num_sims and es[1] == n_balls and es[2] == n_balls\n",
        "else:\n",
        "    import pickle\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "\n",
        "    with open(save_data_file_name, 'rb') as fo:\n",
        "        saved_data = pickle.load(fo)\n",
        "        loc_train = saved_data['loc_train']\n",
        "        vel_train = saved_data['vel_train']\n",
        "        edges_train = saved_data['edges_train']\n",
        "        loc_valid = saved_data['loc_valid']\n",
        "        vel_valid = saved_data['vel_valid']\n",
        "        edges_valid = saved_data['edges_valid']\n",
        "        loc_test = saved_data['loc_test']\n",
        "        vel_test = saved_data['vel_test']\n",
        "        edges_test = saved_data['edges_test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EqNk9sWHSkrA"
      },
      "outputs": [],
      "source": [
        "#@title Create the train-val-test splits\n",
        "\n",
        "# Split the trajectories (x,y coordinates) \n",
        "# into inputs and targets. Target is the same as \n",
        "# the input, but shifted with 1 (temporal) position\n",
        "\n",
        "loc_train_inputs, loc_train_targets = (\n",
        "    loc_train[:, :-1, :, :], loc_train[:, 1:, :, :])\n",
        "loc_valid_inputs, loc_valid_targets = (\n",
        "    loc_valid[:, :-1, :, :], loc_valid[:, 1:, :, :])\n",
        "loc_test_inputs, loc_test_targets = (\n",
        "    loc_test[:, :-1, :, :], loc_test[:, 1:, :, :])\n",
        "\n",
        "# loc_{split}_inputs.shape: \n",
        "# n_samples x n_timesteps x 2(x,y coords) x n_balls\n",
        "print(\"training data shape: \", loc_train_inputs.shape, loc_train_targets.shape, edges_train.shape)\n",
        "print(\"valid data shape: \", loc_valid_inputs.shape, loc_valid_targets.shape, edges_valid.shape)\n",
        "print(\"test data shape:\", loc_test_inputs.shape, loc_test_targets.shape, edges_valid.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw3V2lj1Ubd8"
      },
      "source": [
        "üëÄ Let's see what the trajectories look like. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "d4P5F30ULUPG"
      },
      "outputs": [],
      "source": [
        "#@title Plot one of the trajectories\n",
        "\n",
        "plt.figure(figsize=(4, 4), dpi=100)\n",
        "axes = plt.gca()\n",
        "axes.set_xlim([-2, 2])\n",
        "axes.set_ylim([-1.5, 1.5])\n",
        "\n",
        "which_set =  \"test\" #@param {type:\"string\"} [\"train\", \"valid\", \"test\"]\n",
        "example_index =  2#@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "if which_set == \"train\":\n",
        "  loc, vel, edges = loc_train, vel_train, edges_train\n",
        "elif which_set == \"val\":\n",
        "  loc, vel, edges = loc_valid, vel_valid, edges_valid\n",
        "else:\n",
        "  loc, vel, edges = loc_test, vel_test, edges_test\n",
        "assert example_index >= 0 and example_index < loc.shape[0], \\\n",
        "    \"Need valid dataset index!\"\n",
        "loc, vel, edges = loc[example_index], vel[example_index], edges[example_index]\n",
        "\n",
        "\n",
        "start = 0.0\n",
        "stop = 1.0\n",
        "number_of_lines= 10\n",
        "cm_subsection = linspace(start, stop, number_of_lines) \n",
        "\n",
        "colors = [ cm.Set1(x) for x in cm_subsection ]\n",
        "\n",
        "def softplus(x):\n",
        "    return np.log(1.0 + np.exp(x))\n",
        "\n",
        "for i in range(loc.shape[-1]):\n",
        "    for t in range(loc.shape[0]):\n",
        "        plt.plot(loc[t, 0, i], loc[t, 1, i], 'o', markersize=3, color=colors[i], alpha=1 -(float(t)/loc.shape[0]))\n",
        "    plt.plot(loc[0, 0, i], loc[0, 1, i], 'o', color=colors[i])\n",
        "  \n",
        "x,y = np.where(edges)\n",
        "edges_all = np.vstack((x,y)).T\n",
        "\n",
        "for i, edge in enumerate(edges_all):\n",
        "    axes.add_line(Line2D([loc[0, 0, edge[0]], \n",
        "                    loc[0, 0, edge[1]]], \n",
        "                   [loc[0, 1, edge[0]], \n",
        "                    loc[0, 1, edge[1]]], \n",
        "                   linewidth=2, color='grey', alpha=0.1))\n",
        "\n",
        "plt.savefig(\"springs.pdf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnN64MCAYg5U"
      },
      "source": [
        "üìú  To sum up, we now have access to the following variables, for each `split` $\\in$ `{train, valid, test}`: \\\\\n",
        "  - `loc_{split}_inputs`: positions for the input data `(n_samples x n_timesteps x 2 x n_balls)` \\\\\n",
        "  - `loc_{split}_targets`: positions for the target data (inputs shifted by 1 position) `(n_samples x n_timesteps x 2 x n_balls)` \\\\\n",
        "  - `edges_{split}`: the ground-truth connectivity used by the simulation (constant across the entire trajectory)` (n_samples x n_balls x n_balls)`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQcej2nv60EB"
      },
      "source": [
        "# üï∏ Part 2: Representing graphs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hraIhj4ochQB"
      },
      "source": [
        "A graph is a mathematical structure described as a tuple $\\mathcal{G} = (V, E)$, where $V$ is a set of nodes and $E \\subseteq (V \\times V$) is the set of edges in the graph. Each pair $(u,v) \\in E$ indicates that nodes $u$ and $v$ are connected.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZH8fgC1BRQh"
      },
      "source": [
        "---\n",
        "\n",
        "**Graph input.** For a graph we represent the node \n",
        "features as a matrix $X \\in \\mathbb{R}^{n \\times d}$, where \n",
        "each row $x_i \\in \\mathbb{R}^d$ represents the features for node $u_i$. \n",
        "\n",
        "To describe the graph connectivity, we can use an **adjacency matrix** $A \\in \\mathbb{R}^{n \\times n}$ where $a_{i,j} = 1$ if there is an edge between nodes $u_i$ and $u_j$, and $a_{i,j} = 0$ otherwise.\n",
        "\n",
        "Another - more compact way - of representing the connectivity is through an **adjacency list** $E \\in \\mathbb{R}^{2 \\times m}$, where $m$ represents the number of edges and $(u_i, u_j) \\in E$ indicates an edge between nodes $u_i$ and $u_j$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XFg8bNlnNk5"
      },
      "source": [
        "**Graph output.** Depending on the problem that we want to solve, graph tasks may be split into 3 categories:\n",
        "\n",
        "* **node-level** classification: we predict an output for each node (left);\n",
        "* **edge-level** classification: we predict an output for each edge (center).\n",
        "* **graph-level** classification: we predict a single output for the entire graph (right);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAmwhHyhoxrd"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1ZGdGCzR6MmQnQZuH__I5JltannhHfjem\"  width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5RE7kZ9pR2x"
      },
      "source": [
        "<details>\n",
        "<summary> üíª <b>Q:</b> Which category does the dynamic modeling of moving particles belong to? </summary>\n",
        "\n",
        " **A:** Our dynamic prediction task aims to output the position of each object at each time step in the future. Thus, we can model this as a **node-level classification problem**.\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M69p3PMugf_t"
      },
      "source": [
        "**`Data` structure.** To process the data more easily, we will use the [`torch_geometric.data.Data`](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data) structure from [Pytorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/), designed to store graph-structured information, and [`torch_geometric.data.Dataset`](...), designed to create custom graph datasets.\n",
        "\n",
        "The code\n",
        "\n",
        "> `graph = Data(x=x, y=y, edge_index=edge_index, ...)`\n",
        "\n",
        "creates a graph with features `x`, labels `y` and the connectivity described as an _adjacency list_ `edge_index`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1-At6xDC7lG"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import Data\n",
        "\n",
        "# Use the Data structure to create a sample graph.\n",
        "graph = Data(x=torch.rand((3,32)), \n",
        "               y=torch.rand((1)), \n",
        "               edge_index=torch.tensor([[0,0,0,1,1,1,2,2,2],[0,1,2,0,1,2,0,1,2]]))\n",
        "\n",
        "print(graph)\n",
        "print(\"Number of nodes:\", graph.num_nodes)\n",
        "print(\"Shape of node features:\", graph.x.shape)\n",
        "print(\"Shape of node labels:\", graph.y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuD59J1pB01Z"
      },
      "source": [
        "**`SpringDataset` structure.** For our custom `SpringDataset` class, we have to implement the following functions:\n",
        "\n",
        "* the constructor, which will provide the input location, target location and the connectivity for all the trajectories in the dataset:\n",
        "\n",
        "> `__init__(self, loc_inputs, loc_targets, edges_train, f)`\n",
        "\n",
        "* a function to indicate the number of samples in the dataset:\n",
        "\n",
        "> `__len__(self)`\n",
        "\n",
        "* a getter function:\n",
        "\n",
        "> `__getitem__(self, idx)`\n",
        "\n",
        "that returns the `idx'`th trajectory of the dataset, in the form of a single graph: `Data(edge_index=edge_index, x=x, y=y, timesteps=timesteps)`, where $x \\in \\mathbb{R}^{n_{nodes}~\\times~(dim~*~n_{timesteps})}$, $y \\in \\mathbb{R}^{n_{nodes}~\\times~dim~\\times~n_{timesteps}}$ and $\\textit{edge}\\_{\\textit{index}} \\in{\\mathbb{R}^{2~\\times~n_{edges}}}$ denotes the connectivity for the entire trajectory. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzVs2yw9lhp3"
      },
      "source": [
        "‚ö†Ô∏è **Note:** The input for our model is a sequence of graphs describing the observed trajectory at each time step. However, in our `SpringDataset`, instead of having a sequence of graphs, one for each timestep, we represent the entire trajectory as a _single graph_, where the node features associated with each node $i$ store information about node $i$ along the entire sequence: $x_i \\in \\mathbb{R}^{dim~*~n_{\\textit{timesteps}}}$. This works since the graph connectivity does not change along the trajectory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCMFrTx-FrrK"
      },
      "source": [
        "üß™ Let's create the datasets based on the trajectories generated above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJMjzLikojvp"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import Dataset\n",
        "\n",
        "class SpringDataset(Dataset):\n",
        "    \"\"\" Dataset to store Spring trajectories. \"\"\"\n",
        "\n",
        "    def __init__(self, loc_inputs, loc_targets, edges, timesteps):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            loc_inputs: location for the input sequence n_sample x n_timesteps x dim x n_nodes\n",
        "            loc_targets: location for the target sequence n_sample x n_timesteps x dim x n_nodes\n",
        "            edges: node connectivity for each trajectory: n_sample x n_nodes x n_nodes\n",
        "            timesteps: the length of the trajectory\n",
        "        \"\"\"\n",
        "        super(SpringDataset, self).__init__()\n",
        "\n",
        "        self.dim = loc_targets.shape[2]\n",
        "        # -> n_samples x n_nodes x dim x n_timesteps\n",
        "        loc_targets = np.transpose(loc_targets,[0,3,2,1]) \n",
        "\n",
        "        # Stack the features for all timesteps, s.t. we can describe the entire\n",
        "        # trajectory as a single graph:\n",
        "        # loc_*: n_samples x n_timesteps x dim x n_nodes ->\n",
        "        #        n_samples x n_nodes x dim x n_timesteps -> \n",
        "        #        n_samples x n_nodes x (dim x n_timesteps).\n",
        "        loc_inputs = np.transpose(loc_inputs,[0,3,2,1])\n",
        "        loc_inputs = loc_inputs.reshape((loc_inputs.shape[0], loc_inputs.shape[1], -1))\n",
        "        \n",
        "        self.edges = edges\n",
        "        self.loc_inputs = loc_inputs\n",
        "        self.loc_targets = loc_targets\n",
        "        self.timesteps = timesteps\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.edges.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        crt_edge_adj = self.edges[idx]\n",
        "        crt_loc_inputs = self.loc_inputs[idx]\n",
        "        crt_loc_targets = self.loc_targets[idx]\n",
        "\n",
        "        # Convert the adjacency matrix to an adjacency list.\n",
        "        edge_index = torch.tensor(np.array(np.where(crt_edge_adj)))\n",
        "        x = torch.tensor(crt_loc_inputs).to(torch.float32) \n",
        "        y = torch.tensor(crt_loc_targets).to(torch.float32) \n",
        "\n",
        "        # Create a graph with `x` as features, `y` as labels and its\n",
        "        # connectivity given by `edge_index`.\n",
        "        graph = Data(edge_index=edge_index, x=x, y=y, timesteps=self.timesteps)\n",
        "        return graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fd3sbc7eSXUr"
      },
      "outputs": [],
      "source": [
        "import pdb\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "# Create one dataset for each split and one data loader for each dataset.\n",
        "\n",
        "BATCH_SIZE = 64#@param {type:\"integer\"}\n",
        "DEVICE = 'cuda'#@param {type:\"string\"}\n",
        "\n",
        "timesteps = loc_train_targets.shape[1]\n",
        "train_dataset = SpringDataset(loc_train_inputs, loc_train_targets, edges_train, timesteps)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "valid_dataset = SpringDataset(loc_valid_inputs, loc_valid_targets, edges_valid, timesteps)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# The test trajectories should be at least 2 times as long as the train/val ones\n",
        "test_dataset = SpringDataset(loc_test_inputs, loc_test_targets, edges_test, 2*timesteps)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oer7_wF9FmU3"
      },
      "source": [
        "Let's explore what we generated:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTkex3neF1G9"
      },
      "outputs": [],
      "source": [
        "# This is a Data object containing the first graph in the train dataset.\n",
        "one_sample_graph = train_dataset[0] \n",
        "\n",
        "# This is a Data object containing a batch of graphs.\n",
        "_, batch_graph = next(enumerate(train_loader))\n",
        "\n",
        "print(\"Num nodes for one graph: \", one_sample_graph.num_nodes)\n",
        "print(\"Num nodes for one batch: \", batch_graph.num_nodes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm60-1mFGNc4"
      },
      "source": [
        "<details>\n",
        "<summary> üíª <b>Q:</b> In our setup, a single batch represents a list of `batch_size` graphs (trajectories). However, when extracting a batch using the Pytorch Geometric `DataLoader`, the output - `batch_graph` - is a single graph (stored in a `Data` object). Why do you think this is the case? </summary>\n",
        "\n",
        " **A:** The way mini-batching works in Graph Neural Networks is by creating a big, sparse graph by concatenating `batch_size` disconnected graphs. For more information please take a look at the next section üòâ.\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8vFqSeKESmq"
      },
      "source": [
        "## üîÜ Optional: Graph mini-batching"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOkvo5p4HjOn"
      },
      "source": [
        "Since we wish to process several graphs at once, we need to store them in batches, to make the computation as efficient as possible. In some cases, creating batches is easy. For example, 32√ó32 images are straightforward to batch because they have the same width and height - resulting in a tensor of dimension  $\\textit{batch_size}~\\times~32~\\times~32$). On the other hand, graphs have different numbers of nodes, which yields adjacency matrices with different shapes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRQky5jkIvef"
      },
      "source": [
        "One solution for this is to create a single sparse graph as the union of all the graphs in the mini-batch as follow:\n",
        "\n",
        "1. stack the features  ùë•  for all the nodes in all the graphs;\n",
        "\n",
        "2. stack the labels  ùë¶  for all the nodes in all the graphs\n",
        "\n",
        "3. stack all the adjacency matrices  ùê¥ùëñ  as diagonal blocks in the new adjacency matrix;\n",
        "\n",
        "This way, we will obtain a new graph containing  $\\sum_{b=1}^{B}|V_i|$  nodes, where $B$  is the batch_size and by  $|V_i|$  we denote the number of nodes in graph $i$ . Note that since no edges connect nodes from different graphs, the information propagation will not be affected by the way we store it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZG7zjAQKOW4"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1RwI0CYA57S0OgLxgHgV6PBFNG9tnGvGR\" width=\"500\">\n",
        "</center>\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Ux65wTJLXCfJ4TI4Up4mCHkaSja8NgrJ\" width=\"500\">\n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ecWWMnLKQRg"
      },
      "source": [
        "As you can see, the resulting matrix contains many zeros (sparse), thus storing the adjacency matrix as a sparse tensor can significantly improve the efficiency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ctcEgLVKUnM"
      },
      "source": [
        "Until now, we have a way to store the graphs in a mini-batch such that they could be efficiently processed. \n",
        "\n",
        "However, we need to also be able to extract information from this structure, to recover the graphs that it contains. For this, we need to remember what initial graph each node belongs to.\n",
        "\n",
        "We will do this by storing a list of indices `(self.batch)`, which map each node in the batch-graph to the initial graph it belong to. For example `batch=[0,0,0,1,1,2,2,2]` indicates that first 3 nodes belong to $G_0$, the next 2 nodes belong to $G_1$ and the last 3 nodes belong to $G_2$.\n",
        "\n",
        "> ‚ö†Ô∏è Luckily all of these are already implemented in Dataset class, so we don't have to implement it from scratch. Let have a look!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZ_IIbvJKjSE"
      },
      "outputs": [],
      "source": [
        "# Show statistics about the new graph built from this batch of graphs.\n",
        "_, batch_graph = next(enumerate(train_loader))\n",
        "\n",
        "print(f\"Batch number_of_nodes: {batch_graph.num_nodes}\")\n",
        "print(f\"Batch features shape: {batch_graph.x.shape}\")\n",
        "print(f\"Batch labels shape: {batch_graph.y.shape}\")\n",
        "\n",
        "print(f\"Batch indices for reconstruction: {batch_graph.batch.numpy()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlBFFUXKyZHW"
      },
      "source": [
        "# üë∂üèª Part 3: Coding our first GNN - a Graph Convolutional Network!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAXvfoQhT095"
      },
      "source": [
        "In order to process the information about particle trajectories, we need a model that can understand and process graph-like inputs. There are multiple flavours of Graph Neural Networks in the literature. We will start with one of the simplest ones: the [Graph Convolutional Network](https://arxiv.org/abs/1609.02907)(GCN)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmVKm-AoVCDU"
      },
      "source": [
        "A GCN layer implements the following update rule:\n",
        "\n",
        "$\\mathbf{X_{k+1}} = MLP_k \\big( \\mathbf{\\tilde{D}}^{-\\frac{1}{2}} \\mathbf{\\tilde{A}} \\mathbf{\\tilde{D}}^{-\\frac{1}{2}} \\mathbf{X_k} \\big)$,\n",
        "\n",
        "where $\\mathbf{A}$ is the adjacency matrix, $\\mathbf{\\tilde{A}} = \\mathbf{A} + \\mathbf{I}$ and $\\mathbf{\\tilde{D}}$ is the degree matrix of $\\mathbf{\\tilde{A}}$.\n",
        "\n",
        "Under the hood, this means that:\n",
        "* messages sent by all _incoming_ neighbours are aggregated by averaging\n",
        "* an MLP projection is then applied.\n",
        "\n",
        "The degree matrix $\\mathbf{\\tilde{D}}$ is used to normalised the adjacency matrix, which helps keep the computation more stable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVmlNit_ucjl"
      },
      "outputs": [],
      "source": [
        "def get_adjacency_matrix(edge_index, num_nodes):\n",
        "    \"\"\" Creates an n_nodes x n_nodes adjacency matrix from the adjacency list.\n",
        "\n",
        "    Args:\n",
        "      edge_index: 2 x n_edges tensor containing the adjacency list\n",
        "      num_nodes: number of nodes\n",
        "    Return:\n",
        "      a_tilde: n_nodes x n_nodes tensor representing the adj matrix + self-loops\n",
        "    \"\"\"\n",
        "    eye_matrix = torch.eye(num_nodes).to(DEVICE)\n",
        "    a_tilde = torch.sparse.LongTensor(edge_index, \n",
        "                          # The A matrix is binary, where 1 indicates an edge.\n",
        "                          torch.ones((edge_index.shape[1])).to(DEVICE), \n",
        "                          torch.Size((num_nodes, num_nodes))\n",
        "                          ).to_dense() + eye_matrix\n",
        "    return a_tilde"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRpd0QW6Xjis"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GCNLayer(nn.Module):\n",
        "    \"\"\"A simple GCN layer implementing the MLP(AX) update rule.\"\"\"\n",
        "\n",
        "    def __init__(self, in_feats: int, out_feats: int, hidden_dim: int):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        self.in_feats = in_feats\n",
        "        self.out_feats = out_feats\n",
        "    \n",
        "        self.linear1 = nn.Linear(self.in_feats, hidden_dim)\n",
        "        self.linear2 = nn.Linear(hidden_dim, self.out_feats)\n",
        "\n",
        "    def forward(self, x, adj_matrix): \n",
        "        \"\"\" \n",
        "          x: n_timesteps x n_nodes x in_feats (feats for one mini-batch graph)\n",
        "          adj_matrix: n_nodes x n_nodes (adj for one mini-batch graph)\n",
        "        \n",
        "          out: n_timesteps x n_nodes x out_feats\n",
        "        \"\"\"\n",
        "\n",
        "        # TASK: aggregate neighbouring messages: D^{-1/2}AD^{-1/2}X\n",
        "        #  ============ YOUR CODE HERE  ============\n",
        "        # x = ...\n",
        "        # ==========================================\n",
        "\n",
        "        # TASK: update the node features using a 2-layer MLP: (MLP_k(X))\n",
        "        #  ============ YOUR CODE HERE  ============\n",
        "        # out = ...\n",
        "        # ==========================================\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSao_EELept5"
      },
      "source": [
        "Let's create a Neural Network that uses GCN Layers, in order to predict the change in position $\\Delta x$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzhEEFjqXkp1"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules.linear import Linear\n",
        "class SimpleGCN(nn.Module):\n",
        "    \"\"\" Simple GCN network containing num_layers GCN layers. \"\"\"\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers=2, adj_type=\"gt\"):\n",
        "        super(SimpleGCN, self).__init__()\n",
        "        # Selects between ground-truth(`gt`) or fully-connected (`fully_graph`)\n",
        "        # node connectivity.\n",
        "        self.adj_type = adj_type\n",
        "        assert adj_type in ['gt', 'fully_graph']\n",
        "        \n",
        "        self.num_layers = num_layers \n",
        "        assert self.num_layers >= 2\n",
        "\n",
        "        # Projects the spatial coordinates (x,y) into a larger space.\n",
        "        self.embed_x = Linear(input_dim, hidden_dim)\n",
        "\n",
        "        # TASK: instantiate (num_layers) GCNLayer(s), each with different parameters\n",
        "        #  ============ YOUR CODE HERE  ============\n",
        "        # self.layers = [...]\n",
        "        # ==========================================\n",
        "        self.layers = nn.ModuleList(self.layers)\n",
        "\n",
        "    def forward(self, input, adj_matrix):\n",
        "        # x: n_timesteps x n_nodes x input_dim\n",
        "        x = self.embed_x(input)\n",
        "\n",
        "        for i in range(self.num_layers-1):\n",
        "          x = self.layers[i](x, adj_matrix)\n",
        "          x = F.relu(x)\n",
        "        x = self.layers[-1](x, adj_matrix)\n",
        "        \n",
        "        # We are predictring the shift in position dx, not the future position.\n",
        "        # To obtain the next prediction, we add the input position.\n",
        "        out = input + x\n",
        "\n",
        "        # out: n_timesteps x n_nodes x output_dim\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsu8n9pTrxe9"
      },
      "source": [
        "‚ö†Ô∏è Note that, since we are interested in solving a **node-level** classification problem, obtaining a prediction for each node is enough. For a **graph-level** classification task, an additional operation which aggregates the information from the entire graph (such as max or mean pooling) would have been necessary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSwRxIJtycxt"
      },
      "source": [
        "## üõ† Training the network for dynamic prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSRUGffZ6Q2h"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = 2\n",
        "OUTPUT_DIM = 2\n",
        "TIMESTEPS = 48"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZpxAKkrfft5"
      },
      "source": [
        "In the physics simulations used to generate our dataset, we assume that the dynamics is Markovian, meaning that we can predict the next step base solely on the last observation. \n",
        "\n",
        "During training, we will thus optimise the network to predict the node features at timestep $t+1$, given the features from timestep $t$. We achieve this by considering `input[0:t]` as input and `input[1:t+1]` as target (see `forward_step_teacher_forcing `function). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0161flTJjsRr"
      },
      "outputs": [],
      "source": [
        "def forward_step_teacher_forcing(batch, model):\n",
        "    \"\"\" One feed-forward step with teacher-forcing (used during TRAINING).\n",
        "\n",
        "    During training, we use a teacher-forcing approach: at each time step t, we\n",
        "    feed as input the real position from the previous timestep t-1.\n",
        "\n",
        "    Output: (pred, target) tuple.\n",
        "    \"\"\"\n",
        "    if model.adj_type == 'gt':\n",
        "        # TASK: create an adjacency matrix from the ground-truth connectivity\n",
        "        # Hint: the ground truth graph is stored in `batch.edge_index` and \n",
        "        # you can use the already-implemented `get_adjacency_matrix()`.\n",
        "        #  ============ YOUR CODE HERE  ============\n",
        "        # adj_matrix = ..\n",
        "        # ==========================================\n",
        "    elif model.adj_type == 'fully_graph':\n",
        "        # TASK: create an adjacency matrix for the fully-connected graph \n",
        "        #  ============ YOUR CODE HERE  ============\n",
        "        # adj_matrix = ..\n",
        "        # ==========================================\n",
        "\n",
        "    # Separate the timesteps dimension:\n",
        "    # n_nodes x (dim * n_timesteps) ->  n_nodes x dim x n_timesteps\n",
        "    feats = batch.x.reshape(batch.x.shape[0], INPUT_DIM, -1)\n",
        "    feats = torch.permute(feats, [2,0,1])\n",
        "\n",
        "    # Run the forward pass for GNN.\n",
        "    \n",
        "    # y_hat: n_timesteps x n_nodes x output_dim\n",
        "    y_hat  = model(feats, adj_matrix)\n",
        "    # y_hat: n_nodes x output_dim x n_timesteps\n",
        "    y_hat = y_hat.permute((1,2,0))\n",
        "    return y_hat, batch.y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRS4veUmjvrx"
      },
      "source": [
        "For the evaluation, we only have access to the initial part of the trajectory. So we will evaluate the model step by step, by feeding as input for timestep $t$ the prediction obtained at timestep $t-1$, instead of the ground-truth position. (see `forward_step_pred` function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2focevEqoQxW"
      },
      "outputs": [],
      "source": [
        "def forward_step_pred(batch, model, timesteps=TIMESTEPS):\n",
        "    \"\"\" One feed-forward step using previous predictions as input (EVAL only),\n",
        "    \n",
        "    Run for the first `timesteps` positions in the input.\n",
        "\n",
        "    Output: (pred, target) tuple.\n",
        "    \"\"\"\n",
        "    if model.adj_type == 'gt':\n",
        "        # TASK: create an adjacency matrix from the ground-truth connectivity\n",
        "        # Hint: the ground truth graph is stored in `batch.edge_index` and \n",
        "        # you can use the already-implemented `get_adjacency_matrix()`.\n",
        "        #  ============ YOUR CODE HERE  ============\n",
        "        # adj_matrix = ..\n",
        "        # ==========================================\n",
        "    elif model.adj_type == 'fully_graph':\n",
        "        # TASK: create an adjacency matrix for the fully-connected graph\n",
        "        #  ============ YOUR CODE HERE  ============\n",
        "        # adj_matrix = ...\n",
        "        # ==========================================\n",
        "\n",
        "    # separate the timesteps dimension\n",
        "    # n_nodes x (dim * n_timesteps) ->  n_nodes x dim x n_timesteps\n",
        "    feats = batch.x.reshape(batch.x.shape[0], INPUT_DIM, -1)[:,:,0].unsqueeze(-1)\n",
        "    feats = torch.permute(feats, [2,0,1])\n",
        "\n",
        "    # Run forward for each timestep, using the previous prediction as input.\n",
        "    all_y_hat = []\n",
        "    for i in range(timesteps):\n",
        "      feats  = model(feats, adj_matrix)\n",
        "      all_y_hat.append(feats)\n",
        "    \n",
        "    all_y_hat = torch.cat(all_y_hat, 0)\n",
        "    all_y_hat = all_y_hat.permute((1,2,0))\n",
        "\n",
        "    # all_y_hat: n_nodes x output_dim x n_timesteps\n",
        "    # If the target sequence is longer, only select first `timesteps` elements.\n",
        "    return all_y_hat, batch.y[:,:,:timesteps]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaTj597EoWa-"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def train_epoch(data_loader, model, optimiser, epoch, loss_fct):\n",
        "    \"\"\" Train the model for one epoch. \"\"\"\n",
        "    model.train()\n",
        "    num_iter = len(data_loader)\n",
        "\n",
        "    for i, batch in enumerate(data_loader):\n",
        "        batch = batch.to(DEVICE)\n",
        "        optimiser.zero_grad()\n",
        "        # For training, we always use teacher forcing.\n",
        "        y_hat, y = forward_step_teacher_forcing(batch, model)\n",
        "        loss = loss_fct(y_hat, y)\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "\n",
        "    return loss.data\n",
        "\n",
        "def eval_epoch(data_loader, model, loss_fct, forward_fct):\n",
        "    \"\"\" Evaluate the model. \"\"\"\n",
        "    model.eval()\n",
        "    num_iter = len(data_loader)\n",
        "    loss_eval = 0\n",
        "\n",
        "    for i, batch in enumerate(data_loader):\n",
        "        # For evaluation, we switch between teacher forcing for validation and\n",
        "        # using previous predictions at test-time.\n",
        "        batch = batch.to(DEVICE)\n",
        "        y_hat, y = forward_fct(batch, model)\n",
        "        loss = loss_fct(y_hat, y)\n",
        "        loss_eval += loss.data\n",
        "\n",
        "    loss_eval /= num_iter\n",
        "    return loss_eval\n",
        "\n",
        "\n",
        "\n",
        "def train_eval_loop(model, train_loader, val_loader, test_loader, \n",
        "               loss_fct, num_epochs=100, lr=0.0005):\n",
        "    \"\"\" Train/evaluate the model for `num_epochs` epochs. \"\"\"\n",
        "    # Instantiate our optimiser.\n",
        "    optimiser = optim.Adam(model.parameters(), lr=lr)\n",
        "    training_stats = None\n",
        "\n",
        "    # Initial evaluation (before training).\n",
        "    val_loss = eval_epoch(\n",
        "        val_loader, model, loss_fct, forward_step_teacher_forcing)\n",
        "    train_loss = eval_epoch(\n",
        "        train_loader, model,loss_fct, forward_step_teacher_forcing)\n",
        "\n",
        "    epoch_stats = {\n",
        "        'train_loss': train_loss.cpu(), 'val_loss': val_loss.cpu(), 'epoch': 0\n",
        "    }\n",
        "    training_stats = update_stats(training_stats, epoch_stats)\n",
        "    print(f\"[Epoch 0]\",\n",
        "          f\"train loss: {train_loss:.5f} val loss: {val_loss:.5f}\")\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "      train_loss  = train_epoch(\n",
        "          train_loader, model, optimiser, epoch, loss_fct)\n",
        "      val_loss = eval_epoch(\n",
        "          val_loader, model, loss_fct, forward_step_teacher_forcing)\n",
        "\n",
        "      if epoch % 10 == 0:\n",
        "        print(f\"[Epoch {epoch+1}]\",\n",
        "              f\"train loss: {train_loss:.5f} val loss: {val_loss:.5f}\")\n",
        "      # Store the loss and the computed metric for the final plot.\n",
        "      epoch_stats = {\n",
        "          'train_loss': train_loss.cpu(), 'val_loss': val_loss.cpu(), 'epoch':epoch+1\n",
        "      }\n",
        "      training_stats = update_stats(training_stats, epoch_stats)\n",
        "\n",
        "    # Only after training has finished, evaluate the model on the test set.\n",
        "    test_loss_long_term = eval_epoch(\n",
        "        test_loader, model,  loss_fct, forward_step_pred)\n",
        "    print(f\"Test metric long-term: {test_loss_long_term:.3f}\")\n",
        "    return training_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_BagNLT7l7p"
      },
      "source": [
        "## üíé Train using the **ground-truth graph**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stfwErgNoUoa"
      },
      "source": [
        "Let's train the model using the connectivity provided by the dataset. This model only needs to learn the way in which two connected particles influence each other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6iE9BrZC9zLy"
      },
      "outputs": [],
      "source": [
        "gcn_hidden_dim = 16#@param {type:\"integer\"}\n",
        "gcn_num_layers = 2#@param {type:\"integer\"}\n",
        "LR = 0.0005#@param {type:\"number\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-woaSx8QnXqK"
      },
      "outputs": [],
      "source": [
        "# Instantiate a model with ground-truth connectivity.\n",
        "\n",
        "# TASK: Instantatie a GNN with ground-truth adjacency connectivity.\n",
        "#  ============ YOUR CODE HERE  ============\n",
        "# model_gnn_gt = ...\n",
        "# ==========================================\n",
        "model_gnn_gt = model_gnn_gt.to(DEVICE)\n",
        "\n",
        "# Train the model.\n",
        "train_stats = train_eval_loop(model_gnn_gt, train_loader, valid_loader, \n",
        "                                  test_loader, loss_fct=F.mse_loss, num_epochs=20,lr=LR)\n",
        "# Visualise the training curve.\n",
        "plot_stats(train_stats, name='GNN_gt', figsize=(5, 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXEG6QztgnSW"
      },
      "source": [
        "## üî≠ Visualising predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJc-Flg3oou3"
      },
      "source": [
        "Let's visualise what the learned trajectories look like, when compared to the ground-truth ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vZP24A6kRiP3"
      },
      "outputs": [],
      "source": [
        "#@title [RUN] Helper to visualise trajectories\n",
        "def visualise_trajectory(trajectory, name=\"\"):\n",
        "    #trajectory: n_nodes x 2 x n_timesteps\n",
        "    plt.figure(figsize=(4, 4), dpi=100)\n",
        "    axes = plt.gca()\n",
        "    axes.set_xlim([-4, 4])\n",
        "    axes.set_ylim([-3, 3])\n",
        "\n",
        "    start = 0.0\n",
        "    stop = 1.0\n",
        "    number_of_lines= 10\n",
        "    cm_subsection = linspace(start, stop, number_of_lines) \n",
        "\n",
        "    colors = [ cm.Set1(x) for x in cm_subsection ]\n",
        "    for i in range(test_sample.num_nodes):\n",
        "        for t in range(num_steps):\n",
        "            plt.plot(trajectory[i, 0, t], trajectory[i, 1, t], 'o', markersize=3, color=colors[i], alpha=1 -(float(t)/trajectory.shape[-1]))\n",
        "        plt.plot(trajectory[i, 0, 0], trajectory[i, 1, 0], 'o', color=colors[i])\n",
        "    plt.title(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CeTJxXQ0GBnh"
      },
      "outputs": [],
      "source": [
        "#@title Plot one of the trajectories\n",
        "\n",
        "example_index = 20#@param {type:\"integer\"}\n",
        "num_steps = 30#@param {type:\"integer\"}\n",
        "\n",
        "assert example_index >= 0 and example_index < len(test_dataset), \\\n",
        "    \"Need valid dataset index!\"\n",
        "\n",
        "test_sample= test_dataset[example_index].to(DEVICE)\n",
        "all_preds_tensor, _ = forward_step_pred(test_sample, model_gnn_gt, num_steps)\n",
        "all_preds = all_preds_tensor.cpu().detach().numpy()\n",
        "all_targets = test_sample.y.cpu()\n",
        "\n",
        "visualise_trajectory(all_preds, name=\"prediction\")\n",
        "visualise_trajectory(all_targets, name=\"ground-truth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYhRbJOs76q3"
      },
      "source": [
        "## ‚õè Train using the **fully-connected** graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR3tXNbRo0XM"
      },
      "source": [
        "The model provided above aligned well with how the simulation is generated. However, we do not always have access to the real connectivity (i.e. we do not always know the rules that underlie the evolution of the particle system). Most of the time, we only get to observe each node _individually_ (that is, the position of the each particle along the trajectory). But without the graph structure provided, we will not be able to apply a graph neural network! The usual workaround in this case is to assume a fully-connected graph, where each pair of particles _might_ influence each other. \n",
        "\n",
        "This translates to having an adjacency matrix full of ones. Let's train such a model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "N0IBYkHBiOtV"
      },
      "outputs": [],
      "source": [
        "gcn_fc_hidden_dim = 17#@param {type:\"integer\"}\n",
        "gcn_fc_num_layers = 2#@param {type:\"integer\"}\n",
        "LR = 0.0005#@param {type:\"number\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcc2TZYJytug"
      },
      "outputs": [],
      "source": [
        "# TASK: Instantiate a model with fully-connected connectivity.\n",
        "# ============ YOUR CODE HERE  ============\n",
        "# model_gnn_fully_graph =\n",
        "# =========================================\n",
        "model_gnn_fully_graph = model_gnn_fully_graph.to(DEVICE)\n",
        "\n",
        "# Train the model.\n",
        "train_stats_fully_graph = train_eval_loop(model_gnn_fully_graph, train_loader, valid_loader, \n",
        "                                  test_loader, loss_fct=F.mse_loss, num_epochs=20,lr=LR)\n",
        "\n",
        "# Visualise the training curve.\n",
        "plot_stats(train_stats_fully_graph, name='GNN_fc', figsize=(5, 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "F8tqVmOkGNqz"
      },
      "outputs": [],
      "source": [
        "#@title Plot one of the trajectories\n",
        "example_index = 2#@param {type:\"integer\"}\n",
        "num_steps = 30#@param {type:\"integer\"}\n",
        "\n",
        "assert example_index >= 0 and example_index < len(test_dataset), \\\n",
        "    \"Need valid dataset index!\"\n",
        "\n",
        "test_sample= test_dataset[example_index].to(DEVICE)\n",
        "# all_preds: num_steps x num_nodes x dim\n",
        "all_preds_tensor, _ = forward_step_pred(test_sample, model_gnn_fully_graph, num_steps)\n",
        "all_preds = all_preds_tensor.cpu().detach().numpy()\n",
        "all_targets = test_sample.y.cpu()\n",
        "\n",
        "visualise_trajectory(all_preds, name=\"prediction\")\n",
        "visualise_trajectory(all_targets, name=\"ground-truth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPALOoM4ysQY"
      },
      "source": [
        "# üí° Part 4: Coding a Message Passing Neural Network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vk6xh0FmqSk9"
      },
      "source": [
        "Until now, we trained GCN models to predict particle trajectories, based on previous observations. One way to improve on this is by using a more powerful Graph Neural Network architecture.\n",
        "\n",
        "One of the most general such architectures is the Message Passing Neural Network. This framework is based on 3 steps:\n",
        "1. for each pair of 2 connected nodes, create a **message**;\n",
        "2. for each node, **aggregate** the messages from its neighbourhood; \n",
        "3. **update** each node's representation using the corresponding aggregated messages.\n",
        "\n",
        "The steps above are summarised by the following equation:\n",
        "\n",
        "\\begin{equation}\n",
        "X_{k+1} = MLP_{upd}(\\frac{1}{n_{edges}} \\sum_j{MLP_{msg}({X_k}_i, {X_k}_j)})\n",
        "\\end{equation}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4on0LuifKone"
      },
      "outputs": [],
      "source": [
        "class MPNNLayer(nn.Module):\n",
        "    \"\"\" A Message Passing Layer. \"\"\"\n",
        "    def __init__(self, in_feats: int, out_feats: int, hidden_dim: int):\n",
        "        super(MPNNLayer, self).__init__()\n",
        "        self.in_feats = in_feats\n",
        "        self.out_feats = out_feats\n",
        "    \n",
        "        # Params for the nodes->edges function.\n",
        "        self.linear1 = nn.Linear(self.in_feats, hidden_dim)\n",
        "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "        # Params for the edges->nodes function.\n",
        "        self.linear3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.linear4 = nn.Linear(hidden_dim, self.out_feats)\n",
        "\n",
        "    def forward(self, x, adj_matrix): \n",
        "        # x: n_timesteps x n_nodes (for the whole batch) x dim\n",
        "        # adj_matrix: n_nodes x n_nodes\n",
        "        \n",
        "        adj_matrix = adj_matrix.unsqueeze(0).unsqueeze(-1)\n",
        "\n",
        "        # Create messages for each pair of connected nodes.\n",
        "        # We achieve all pairs of nodes (i,j) via broadcasting, by concatenating\n",
        "        # (n_nodes x 1 x dim) || (1 x n_nodes x dim) -> (n_nodes x n_nodes x dim)\n",
        "        feats_source = x.unsqueeze(2).tile((1,1,x.shape[1],1)) # n_timesteps x n_nodes x 1 x dim\n",
        "        feats_dest =  x.unsqueeze(1).tile((1,x.shape[1],1,1)) # n_timesteps x 1 x n_nodes x dim\n",
        "        feats_msg = torch.concat((feats_source, feats_dest), dim=-1) # n_timesteps x n_nodes x n_nodes x 2*dim\n",
        "\n",
        "        # TASK: update the messages for each pair of nodes using a 2 layer MLP\n",
        "        #  ============ YOUR CODE HERE  ============\n",
        "        # feats_msg = ..\n",
        "        #  =========================================\n",
        "\n",
        "        # To take into account the provided connectivity, mask the resulting\n",
        "        # tensor with the adjacency matrix.\n",
        "        feats_msg = feats_msg * adj_matrix  # n_timesteps x n_nodes x n_nodes x 2*dim \n",
        "\n",
        "        # Aggregate incoming messages via average pooling.\n",
        "        feats_node = feats_msg.sum(axis=1) \n",
        "        feats_node = feats_node / adj_matrix.sum(1)\n",
        "\n",
        "        # TASK: Update the node representation using a 2 layers MLP.\n",
        "        #  ============ YOUR CODE HERE  ============\n",
        "        # feats_node = ..\n",
        "        feats_node = F.relu(self.linear3(feats_node))\n",
        "        feats_node = self.linear4(feats_node)\n",
        "        #  =========================================\n",
        "\n",
        "        return feats_node"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iat9OUTDs-fL"
      },
      "source": [
        "Let's create a Neural Network that uses MPNN Layers, in order to predict the change in position  Œîùë• :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTyt0fTHQCgn"
      },
      "outputs": [],
      "source": [
        "class SimpleMPNN(nn.Module):\n",
        "    \"\"\" Simple MPNN network containing num_layers MPNN layers. \"\"\"\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers=2, adj_type=\"gt\"):\n",
        "        super(SimpleMPNN, self).__init__()\n",
        "        # Selects between ground-truth(gt) or fully-connected (fully_graph) node\n",
        "        # connectivity.\n",
        "        self.adj_type = adj_type\n",
        "        assert adj_type in ['gt', 'fully_graph', '?']\n",
        "        \n",
        "        # NOTE: please select num_layers >= 2!\n",
        "        self.num_layers = num_layers \n",
        "\n",
        "        # Project the spatial coordinates (x,y) into a larger space .\n",
        "        self.embed_x = Linear(input_dim, hidden_dim)\n",
        "\n",
        "        # TASK: instantiate `num_layers` MPNNLayer(s), each having a different set of parameters\n",
        "        # ============ YOUR CODE HERE  ============\n",
        "        # self.layers = nn.ModuleList(...)\n",
        "        # =========================================\n",
        "\n",
        "    def forward(self, input, adj_matrix):\n",
        "        # x: n_timesteps x n_nodes x dim\n",
        "        x = self.embed_x(input)\n",
        "\n",
        "        for i in range(self.num_layers-1):\n",
        "          x = self.layers[i](x, adj_matrix)\n",
        "          x = F.relu(x)\n",
        "        x = self.layers[-1](x, adj_matrix)\n",
        "        \n",
        "        # We are predicting the shift dx, not the future position. To obtain the\n",
        "        # next prediction, add the input position.\n",
        "        out = input + x\n",
        "\n",
        "        # out: n_timesteps x n_nodes x dim\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHYHwBcp8O6-"
      },
      "source": [
        "## üõ† Train an MPNN for dynamic prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkkYwKfqtQDs"
      },
      "source": [
        "Let's train the model using the fully-connected graph. Despite our assumption about the structure, note that the MPNN is able to filter the neighbouring messages via `MLP_msg`, thus improving on the original connectivity. Unlike the MPNN, the GCN always aggregates messages from _all_ neighbours, which might lead to problems in the fully-connected setup!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BWIUsQIh-T82"
      },
      "outputs": [],
      "source": [
        "mpnn_hidden_dim = 17#@param {type:\"integer\"}\n",
        "mpnn_num_layers =  2#@param {type:\"integer\"}\n",
        "LR = 0.0005#@param {type:\"number\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9sLO8y6QacW"
      },
      "outputs": [],
      "source": [
        "# TASK: Instantiate an MPNN model with fully-connected structure.\n",
        "# ============ YOUR CODE HERE  ============\n",
        "# model_mpnn_gt = \n",
        "# =========================================\n",
        "model_mpnn_gt = model_mpnn_gt.to(DEVICE)\n",
        "\n",
        "# Train the model.\n",
        "train_stats = train_eval_loop(model_mpnn_gt, train_loader, valid_loader, \n",
        "                                  test_loader, loss_fct=F.mse_loss, num_epochs=20,lr=LR)\n",
        "\n",
        "# Visualise the training curve.\n",
        "plot_stats(train_stats, name='MPNN_fc', figsize=(5, 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4bfF-B3DC7_"
      },
      "source": [
        "## üî≠ Visualise the predicted trajectories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UGF7KIU5y6Tf"
      },
      "outputs": [],
      "source": [
        "#@title Plot one of the trajectories\n",
        "example_index = 2#@param {type:\"integer\"}\n",
        "num_steps = 30#@param {type:\"integer\"}\n",
        "\n",
        "assert example_index >= 0 and example_index < len(test_dataset), \\\n",
        "    \"Need valid dataset index!\"\n",
        "\n",
        "test_sample= test_dataset[example_index].to(DEVICE)\n",
        "all_preds_tensor, _ = forward_step_pred(test_sample, model_mpnn_gt, num_steps)\n",
        "all_preds = all_preds_tensor.cpu().detach().numpy()\n",
        "all_targets = test_sample.y.cpu()\n",
        "\n",
        "visualise_trajectory(all_preds, name=\"prediction\")\n",
        "visualise_trajectory(all_targets, name=\"ground-truth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EhFLeXNp6v1"
      },
      "source": [
        "# üÜí BONUS: Predict the connectivity with an NRI-like model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHwvDC36vnXD"
      },
      "source": [
        "Without knowing the graph structure, assuming fully-connected interaction is a simple but _very weak_ prior. A different approach is learning to _predict_ the connectivity and use this predicted structure during graph processing. \n",
        "\n",
        "However, if the ground-truth connectivity is not available, we need to design an end-to-end differentiable graph predictor such that the graph connectivity is learned using only the final, node-level supervision.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOBHFVm_y53W"
      },
      "source": [
        "**Architecture.** One of the most popular approaches for this task is the Neural Relation Inference (NRI) model, which contains 2 parts:\n",
        "\n",
        "1) An **encoder**, to predict the graph connectivity;\n",
        "\n",
        "2) A **decoder**, which uses the connectivity predicted by the encoder to predict the trajectory (similar to the models used before)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iNnbKrEAja-"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1t0AKZOzv43NhfBx4gbIMPhTuO2dRuPN3\" width=\"800\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5p7ZlNBy1yZ"
      },
      "source": [
        "For the encoder architecture we will adopt an MPNN architecture that tries to predict the graph structure based on a sequence of observations.\n",
        "\n",
        "The model receives as input a single fully-connected graph. The features for each particle / node are obtained by concatenating the features for that particle along the trajectory $x_i \\in \\mathbb{R}^{2~\\times~n_{timesteps}} $. Instead of predicting the features for each node, the encoder uses the representation of each pair of nodes to predict a score. This score, given by the equation below, is then used to _sample_ the graph structure.\n",
        "\n",
        "\\begin{equation}\n",
        "h_{i,j} = \\text{softmax}(\\text{MLP}_{edge}(h_i, h_j))\n",
        "\\end{equation}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7e1yEVzA_Ma"
      },
      "source": [
        "\n",
        "For each edge, scores obtained by the encoder are used to sample the graph structure (0/1 denoting the absence/presence of the edge). However, the classical operation of sampling from a distribution is not differentiable. To be able to backpropagate the gradient through the model, we will used [Gumble Softmax](https://en.wikipedia.org/wiki/Gumbel_distribution) as a sampler (a relaxed version of the categorical distribution):\n",
        "\n",
        "\\begin{equation}\n",
        "  g_k = \\text{Gumble}(0,1) \\\\\n",
        "  z_{i,j} = \\text{softmax}((h_{i,j} + g) / \\tau) \n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZoQfH7quSkI"
      },
      "outputs": [],
      "source": [
        "class EdgeMPNNLayer(nn.Module):\n",
        "    \"\"\" An MPNN layer producing a representation for each edge h_{i,j}. \"\"\"\n",
        "    def __init__(self, in_feats: int, out_feats: int, hidden_dim: int):\n",
        "        super(EdgeMPNNLayer, self).__init__()\n",
        "        self.in_feats = in_feats\n",
        "        self.out_feats = out_feats\n",
        "    \n",
        "        self.linear1 = nn.Linear(self.in_feats, hidden_dim)\n",
        "        self.linear2 = nn.Linear(hidden_dim, 2) # edge or no edge\n",
        "\n",
        "    def forward(self, x, adj_matrix): \n",
        "        # x: n_nodes (for the whole batch) x dim\n",
        "        # adj_matrix: n_nodes x n_nodes\n",
        "        adj_matrix = adj_matrix.unsqueeze(-1)\n",
        "        \n",
        "        # Create messages for each pair of connected nodes\n",
        "        # we achieve all pairs of nodes (i,j) via broadcasting by concatenating\n",
        "        # (n_nodes x 1 x dim) || (1 x n_nodes x dim) -> (n_nodes x n_nodes x dim)\n",
        "        feats_source = x.unsqueeze(1).tile((1,x.shape[0],1)) # n_nodes x 1 x dim\n",
        "        feats_dest =  x.unsqueeze(0).tile((x.shape[0],1,1)) # 1 x n_nodes x dim\n",
        "        feats_msg = torch.concat((feats_source, feats_dest), dim=-1) # n_nodes x n_nodes x 2*dim\n",
        "\n",
        "        # TASK: update the messages for each pair of nodes using a 2 layer MLP\n",
        "        # ============ YOUR CODE HERE  ============\n",
        "        # feats_msg = ..\n",
        "        # =========================================\n",
        "\n",
        "        # To account for the provided connectivity, we masked the resulting\n",
        "        # tensor with the adjacency matrix. The 2 outputs (logits) correspond to\n",
        "        # probabilities of (not) having an edge between (i,j).\n",
        "\n",
        "        # By default, `adj_matrix` is a matrix full of ones.\n",
        "        feats_msg = feats_msg * adj_matrix  # n_nodes x n_nodes x 2\n",
        "\n",
        "        return feats_msg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdcNZpGuy6Vv"
      },
      "outputs": [],
      "source": [
        "class SimpleMPNNEncoder(nn.Module):\n",
        "    \"\"\" The MPNN Encoder predicting the graph structure. \"\"\"\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers=2):\n",
        "        super(SimpleMPNNEncoder, self).__init__()\n",
        "        \n",
        "        self.num_layers = num_layers  \n",
        "        assert self.num_layers >= 2\n",
        "\n",
        "        self.embed_x = Linear(input_dim, hidden_dim)\n",
        "\n",
        "        # TASK: instantiate `num_layers-1` MPNNLayer(s), each having a different set of parameters\n",
        "        # ============ YOUR CODE HERE  ============\n",
        "        # self.layers = ..\n",
        "        # =========================================\n",
        "\n",
        "        # TASK: The last layer is an EdgeMPNNLayer for edge-level predictions.\n",
        "        # ============ YOUR CODE HERE  ============\n",
        "        # self.layers += ..\n",
        "        # =========================================\n",
        "        self.layers = nn.ModuleList(self.layers)\n",
        "\n",
        "    def forward(self, input):\n",
        "        adj_matrix = torch.ones((input.shape[1], input.shape[1])).to(DEVICE)\n",
        "        # x: n_timesteps x n_nodes x dim ->  n_nodes x dim x n_timesteps\n",
        "        x = torch.permute(input, (1,2,0)).contiguous()\n",
        "        \n",
        "        # Merge the last 2 dimension. The graph prediction should be made based\n",
        "        # on the entire sequence.\n",
        "        x = x.view((x.shape[0],-1))\n",
        "        x = self.embed_x(x).unsqueeze(0)\n",
        "\n",
        "        for i in range(self.num_layers-1):\n",
        "          x = self.layers[i](x, adj_matrix)\n",
        "          x = F.relu(x)\n",
        "        \n",
        "        # x: 1 x n_nodes x dim\n",
        "        x = x.squeeze(0)\n",
        "        out = self.layers[-1](x, adj_matrix)\n",
        "        # out: n_nodes x n_nodes x 2\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g9LWRUuHqoM"
      },
      "source": [
        "We provide the code for the Gumble softmax sampling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ch2QSHa12Cd",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title [RUN] helper functions for sampling the adjacency\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "def my_softmax(input, axis=1):\n",
        "    soft_max_1d = F.softmax(input, axis)\n",
        "    return soft_max_1d \n",
        "    \n",
        "def sample_gumbel(shape, eps=1e-10):\n",
        "    \"\"\"\n",
        "    NOTE: Taken from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
        "    Sample from Gumbel(0, 1)\n",
        "    based on\n",
        "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,\n",
        "    (MIT license)\n",
        "    \"\"\"\n",
        "    U = torch.rand(shape).float()\n",
        "    gumbels = - torch.log(eps - torch.log(U + eps))\n",
        "    return gumbels\n",
        "\n",
        "\n",
        "def gumbel_softmax_sample(logits, tau=1, eps=1e-10):\n",
        "    \"\"\"\n",
        "    NOTE: Taken from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
        "    Draw a sample from the Gumbel-Softmax distribution\n",
        "    based on\n",
        "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb\n",
        "    (MIT license)\n",
        "    \"\"\"\n",
        "    gumbel_noise = sample_gumbel(logits.size(), eps=eps)\n",
        "    y = logits + Variable(gumbel_noise).to(DEVICE)\n",
        "    return my_softmax(y / tau, axis=-1)\n",
        "\n",
        "\n",
        "def gumbel_softmax(logits, tau=1, hard=False, eps=1e-10):\n",
        "    \"\"\"\n",
        "    NOTE: Taken from https://github.com/pytorch/pytorch/pull/3341/commits/327fcfed4c44c62b208f750058d14d4dc1b9a9d3\n",
        "    Sample from the Gumbel-Softmax distribution and optionally discretize.\n",
        "    Args:\n",
        "      logits: [batch_size, n_class] unnormalized log-probs\n",
        "      logits: [num_timesteps, n_nodes, n_nodes, 2] unnormalized log-probs\n",
        "      tau: non-negative scalar temperature\n",
        "      hard: if True, take argmax, but differentiate w.r.t. soft sample y\n",
        "    Returns:\n",
        "      [batch_size, n_class] sample from the Gumbel-Softmax distribution.\n",
        "      If hard=True, then the returned sample will be one-hot, otherwise it will\n",
        "      be a probability distribution that sums to 1 across classes\n",
        "    Constraints:\n",
        "    - this implementation only works on batch_size x num_features tensor for now\n",
        "    based on\n",
        "    https://github.com/ericjang/gumbel-softmax/blob/3c8584924603869e90ca74ac20a6a03d99a91ef9/Categorical%20VAE.ipynb ,\n",
        "    (MIT license)\n",
        "    \"\"\"\n",
        "    y_soft = gumbel_softmax_sample(logits, tau=tau, eps=eps)\n",
        "    if hard:\n",
        "        shape = logits.size()\n",
        "        _, k = y_soft.data.max(-1)\n",
        "        # this bit is based on\n",
        "        # https://discuss.pytorch.org/t/stop-gradients-for-st-gumbel-softmax/530/5\n",
        "        y_hard = torch.zeros(*shape).to(DEVICE)\n",
        "        y_hard = y_hard.zero_().scatter_(-1, k.view(shape[:-1] + (1,)), 1.0).to(DEVICE)\n",
        "        # this cool bit of code achieves two things:\n",
        "        # - makes the output value exactly one-hot (since we add then\n",
        "        #   subtract y_soft value)\n",
        "        # - makes the gradient equal to y_soft gradient (since we strip\n",
        "        #   all other gradients)\n",
        "        y = Variable(y_hard - y_soft.data).to(DEVICE) + y_soft\n",
        "    else:\n",
        "        y = y_soft\n",
        "    return y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz8ZsZQaHvIy"
      },
      "source": [
        "Let's use the encoder-decoder architecture to predict the trajectories. We will modify the forward pass such that it first predicts the adjacency matrix and then uses it to indicate the connectivity, instead of what `adj_type` suggests.\n",
        "\n",
        "**Training procedure.** Following the approach used in the original paper, during *training*, both the encoder and the decoder receive as input the entire trajectory. For the final *evaluation* to be applicable in practice, the encoder receives only the first half of the trajectory, while the decoder predicts the other half."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyZSITA2y6Xr"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def forward_step_teacher_forcing_nri(batch, model_adj, model):\n",
        "    \"\"\" One feed-forward step using teacher-forcing (TRAIN only).\n",
        "\n",
        "    During training, we use a teacher-forcing approach, where at each time step\n",
        "    t, we feed as input the real position from the previous timestep t-1.\n",
        "\n",
        "    The model is an encoder-decoder architecture: \n",
        "    - first, the encoder predicts the structure probabilities;\n",
        "    - then, the Gumbel Softmax is used to sample the structure;\n",
        "    - finally, the predicted structure is used to predict the trajectory.\n",
        "\n",
        "    Output: (pred, target) tuple.\n",
        "    \"\"\"\n",
        "\n",
        "    # During training, the encoder receives the whole trajectory.\n",
        "    feats = batch.x.reshape(batch.x.shape[0], INPUT_DIM, -1)\n",
        "    feats = torch.permute(feats, [2,0,1])\n",
        "\n",
        "    # Encoder: predict the graph structure.\n",
        "    adj_matrix = model_adj(feats) #n_nodes x n_nodes x 2\n",
        "    adj_matrix = gumbel_softmax(adj_matrix, tau=1, hard=True)\n",
        "    # Since we only have one type of edge, we can do this.\n",
        "    adj_matrix = adj_matrix[:,:,0] + torch.eye(batch.num_nodes).to(DEVICE) #n_nodes x n_nodes\n",
        "\n",
        "    # Decoder: uses the predicted structure to predict the trajectory.\n",
        "    y_hat  = model(feats, adj_matrix)\n",
        "    y_hat = y_hat.permute((1,2,0))\n",
        "    return y_hat, batch.y\n",
        "\n",
        "def forward_step_pred_nri(batch, model_adj, model, timesteps=TIMESTEPS):\n",
        "    \"\"\" One feed-forward step using previous predictions as inputs (EVAL only);\n",
        "   `run for the first `timesteps` position in the input.\n",
        "\n",
        "    During training, we use a teacher-forcing approach, where at each time step\n",
        "    t, we feed as input the real position from the previous timestep t-1.\n",
        "\n",
        "    The model is an encoder-decoder architecture: \n",
        "    - first, the encoder predicts the structure probabilities;\n",
        "    - then, the Gumbel Softmax is used to sample the structure;\n",
        "    - finally, the predicted structure is used to predict the trajectory.\n",
        "\n",
        "    Output: (pred, target) tuple.\n",
        "    \"\"\"\n",
        "\n",
        "    feats = batch.x.reshape(batch.x.shape[0], INPUT_DIM, -1)\n",
        "    # feats: n_nodes x dim x n_timesteps\n",
        "    assert(feats.shape[-1] >= 2*timesteps)\n",
        "\n",
        "    # During testing, the encoder receives the first half of the trajectory.\n",
        "    feats_enc = feats[:,:,:timesteps]\n",
        "    # The decoder predicts the second half of the trajectory.\n",
        "    feats_dec = feats[:,:,-timesteps:]\n",
        "  \n",
        "    feats_enc = torch.permute(feats_enc, [2,0,1])\n",
        "    feats_dec = torch.permute(feats_dec, [2,0,1])[0,:,:].unsqueeze(0)\n",
        "    \n",
        "    # Encoder: predict the graph structure.\n",
        "    adj_matrix = model_adj(feats_enc)\n",
        "    adj_matrix = gumbel_softmax(adj_matrix, tau=1, hard=True)\n",
        "    # Since we only have one type of edge, we can extract the probability of\n",
        "    # existence from the first position.\n",
        "    adj_matrix = adj_matrix[:,:,0] + torch.eye(batch.num_nodes).to(DEVICE)\n",
        "\n",
        "    # Decoder: uses the predicted structure to predict the trajectory.\n",
        "    all_y_hat = []\n",
        "    for i in range(timesteps):\n",
        "      feats_dec  = model(feats_dec, adj_matrix)\n",
        "      all_y_hat.append(feats_dec)\n",
        "    \n",
        "    all_y_hat = torch.cat(all_y_hat, 0)\n",
        "    all_y_hat = all_y_hat.permute((1,2,0))\n",
        "\n",
        "    # n_nodes x dim x n_timesteps\n",
        "    return all_y_hat, batch.y[:,:,-timesteps:]\n",
        "\n",
        "def train_epoch_nri(data_loader, model_adj, model, optimiser, epoch, loss_fct):\n",
        "    \"\"\" Train the model for one epoch. \"\"\"\n",
        "    model.train()\n",
        "    num_iter = len(data_loader)\n",
        "\n",
        "    for i, batch in enumerate(data_loader):\n",
        "        batch = batch.to(DEVICE)\n",
        "        optimiser.zero_grad()\n",
        "        # For training, we are always using teacher forcing.\n",
        "        y_hat,y = forward_step_teacher_forcing_nri(batch, model_adj, model)\n",
        "        loss = loss_fct(y_hat, y)\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "\n",
        "    return loss.data\n",
        "\n",
        "def eval_epoch_nri(data_loader, model_adj, model, loss_fct, forward_fct):\n",
        "    \"\"\" Evaluate the model on the dataset. \"\"\"\n",
        "    model.eval()\n",
        "    num_iter = len(data_loader)\n",
        "    loss_eval = 0\n",
        "\n",
        "    for i, batch in enumerate(data_loader):\n",
        "        # For evaluation, we can switch between using the gt (teacher forcing)\n",
        "        # or the prediction as an input to the next state.\n",
        "        batch = batch.to(DEVICE)\n",
        "        y_hat,y = forward_fct(batch, model_adj, model)\n",
        "        loss = loss_fct(y_hat, y)\n",
        "        loss_eval += loss.data\n",
        "\n",
        "    loss_eval /= num_iter\n",
        "    return loss_eval\n",
        "\n",
        "def train_eval_loop_nri(model_adj, model, train_loader, val_loader, test_loader, \n",
        "               loss_fct, num_epochs=100,lr=0.0005):\n",
        "    \"\"\" Train the model for num_epochs epochs. \"\"\"\n",
        "    # Instantiatie our optimiser.\n",
        "    optimiser = optim.Adam(\n",
        "        list(model.parameters()) + list(model_adj.parameters()), lr=lr)\n",
        "    training_stats = None\n",
        "\n",
        "    # Initial evaluation (before training).\n",
        "    val_loss = eval_epoch_nri(val_loader,\n",
        "                              model_adj,\n",
        "                              model,\n",
        "                              loss_fct,\n",
        "                              forward_step_teacher_forcing_nri)\n",
        "    train_loss = eval_epoch_nri(train_loader,\n",
        "                                model_adj,\n",
        "                                model,\n",
        "                                loss_fct,\n",
        "                                forward_step_teacher_forcing_nri)\n",
        "\n",
        "    \n",
        "    epoch_stats = {\n",
        "        'train_loss': train_loss.cpu(), 'val_loss': val_loss.cpu(), 'epoch': 0\n",
        "    }\n",
        "    training_stats = update_stats(training_stats, epoch_stats)\n",
        "    print(f\"[Epoch 0]\",\n",
        "          f\"train loss: {train_loss:.5f} val loss: {val_loss:.5f}\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss  = train_epoch_nri(train_loader,\n",
        "                                      model_adj,\n",
        "                                      model,\n",
        "                                      optimiser,\n",
        "                                      epoch, \n",
        "                                      loss_fct)\n",
        "        \n",
        "        val_loss = eval_epoch_nri(val_loader,\n",
        "                                  model_adj,\n",
        "                                  model,\n",
        "                                  loss_fct,\n",
        "                                  forward_step_teacher_forcing_nri)\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "          print(f\"[Epoch {epoch+1}]\",\n",
        "                f\"train loss: {train_loss:.5f} val loss: {val_loss:.5f}\")\n",
        "        # Store the loss and the computed metric for the final plot.\n",
        "        epoch_stats = {\n",
        "            'train_loss': train_loss.cpu(), 'val_loss': val_loss.cpu(), 'epoch': epoch + 1\n",
        "        }\n",
        "        training_stats = update_stats(training_stats, epoch_stats)\n",
        "    \n",
        "    # Evaluate the model on the test split\n",
        "    test_loss_long_term = eval_epoch_nri(\n",
        "        test_loader, model_adj, model,  loss_fct, forward_step_pred_nri)\n",
        "    print(f\"Test metric long term: {test_loss_long_term:.3f}\")\n",
        "    return training_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e8pLE7R87Kr"
      },
      "source": [
        "## üõ† Train the NRI model with simple MSE loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLxj7r21y_LM"
      },
      "source": [
        "Let's train the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ejYgYCN_-jvK"
      },
      "outputs": [],
      "source": [
        "nri_simple_hidden_dim = 16#@param {type:\"integer\"}\n",
        "nri_simple_num_layers = 2#@param {type:\"integer\"}\n",
        "LR = 0.0005#@param {type:\"number\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oge3cNlsy6Z0"
      },
      "outputs": [],
      "source": [
        "# TASK: Instantiate the MPNN Decoder (same as the one used before) and the MPNN Encoder. ; `adj_type` is\n",
        "# ignored since we are using the predicted one.\n",
        "# ============ YOUR CODE HERE  ============\n",
        "# model_nri = ..\n",
        "# model_adj_nri = ..\n",
        "# ==========================================\n",
        "model_nri = model_nri.to(DEVICE)\n",
        "model_adj_nri = model_adj_nri.to(DEVICE)\n",
        "\n",
        "# Train the model.\n",
        "train_stats = train_eval_loop_nri(model_adj_nri, model_nri, train_loader, valid_loader, \n",
        "                                  test_loader, loss_fct=F.mse_loss, num_epochs=20,lr=LR)\n",
        "\n",
        "# Plot the training curve.\n",
        "plot_stats(train_stats, name='MPNN_nri', figsize=(5, 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUr-urit9DDE"
      },
      "source": [
        "## üî≠ Visualise the trajectories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "B8JyaYQoy6br"
      },
      "outputs": [],
      "source": [
        "#@title Plot one of the trajectories\n",
        "example_index = 13#@param {type:\"integer\"}\n",
        "\n",
        "assert example_index >= 0 and example_index < len(test_dataset), \\\n",
        "    \"Need valid dataset index!\"\n",
        "\n",
        "test_sample= test_dataset[example_index].to(DEVICE)\n",
        "# all_preds: n_timesteps x n_nodes x dim\n",
        "all_preds_tensor, all_targets_tensor = forward_step_pred_nri(test_sample, model_adj_nri, model_nri)\n",
        "all_preds = all_preds_tensor.cpu().detach().numpy()\n",
        "\n",
        "all_targets = all_targets_tensor.cpu().detach().numpy()\n",
        "\n",
        "visualise_trajectory(all_preds, name=\"prediction\")\n",
        "visualise_trajectory(all_targets, name=\"ground-truth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtbKIq-ayes-"
      },
      "source": [
        "## üõ† Train NRI with ELBO loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yeNvoyPzJEt"
      },
      "source": [
        "**ELBO loss function.** The original NRI model formalises the training as a variational autoencoder (VAE), using ELBO as an objective:\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1n7VDaebgX2EOSl_KtKYgEtjgTA7NjwTt\" width=\"500\">\n",
        "</center>\n",
        "\n",
        "The first term is a **reconstruction** term, ensuring that the prediction is accurate, while the second term is a **regularisation** term, ensuring that the distribution of the graph is close to the prior.\n",
        "\n",
        "The reconstruction term could be estimated by\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1CJYp5sjvp2LmX33OSxlYkQfQHpJWNscs\" width=\"250\">\n",
        "</center>\n",
        "\n",
        "For an uniform prior, the second term becomes the sum of the entropies:\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1_f6AKWpmrmrS88PGEjdxUZHsjzKtFT3m\" width=\"250\">\n",
        "</center>\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aeuzc2pW0BNW"
      },
      "source": [
        "<details>\n",
        "<summary> üíª <b>Q:</b> Try to prove that the KL loss for the uniform prior leads to the sum of entropies (plus a constant). </summary>\n",
        "\n",
        " **A:** \n",
        " \n",
        " \\begin{align}\n",
        " KL(q(z|x)||u(z)) &= \\sum_z q(z|x) log(\\frac{q(z|x)}{u(z)}) \\\\\n",
        "  &= \\sum_z q(z|x) log(q(z|x))-\\sum_z q(z|x)log({u(z)}) \\\\ \n",
        "  &=\\sum_z q(z|x) log(q(z|x))-\\sum_z q(z|x)log(\\frac{1}{2})) \\\\\n",
        "  &=\\sum_z q(z|x) log(q(z|x))+\\sum_z q(z|x)log(2) \\\\\n",
        "  &=\\sum_z q(z|x) log(q(z|x))+log(2) \\\\\n",
        "  &=-H(q(z|x))+log(2) \\\\\n",
        " \\end{align}\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9czFJaY4BZK"
      },
      "outputs": [],
      "source": [
        "def kl_categorical_uniform(preds, num_nodes, eps=1e-16):\n",
        "    preds = preds.view(-1, preds.shape[-1])\n",
        "    kl_div = preds * torch.log(preds + eps)\n",
        "    return kl_div.sum() / (num_nodes * preds.size(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpXxC4C3y6dq"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def forward_step_teacher_forcing_nri_elbo(batch, model_adj, model):\n",
        "    # For training, use the whole sequence to predict the graph structure.\n",
        "    feats = batch.x.reshape(batch.x.shape[0], INPUT_DIM, -1)\n",
        "    feats = torch.permute(feats, [2,0,1])\n",
        "\n",
        "    # Encoder: predict the graph structure.\n",
        "    adj_matrix_logits = model_adj(feats) # n_nodes x n_nodes x 2\n",
        "    adj_matrix = gumbel_softmax(adj_matrix_logits, tau=1, hard=True)\n",
        "    adj_matrix_prob = my_softmax(adj_matrix_logits, -1) # n_nodes x n_nodes x 2\n",
        "\n",
        "    \n",
        "    # Since we only have one type of edge, we can extract the probability of\n",
        "    # an edge from the first position.\n",
        "    adj_matrix = adj_matrix[:,:,0]\n",
        "\n",
        "    # Decoder: uses the predicted structure to predict the trajectory.\n",
        "    y_hat  = model(feats, adj_matrix)\n",
        "    y_hat = y_hat.permute((1,2,0))\n",
        "    return y_hat, batch.y[:,:,-timesteps:], adj_matrix_prob\n",
        "\n",
        "def forward_step_pred_nri_elbo(batch, model_adj, model, timesteps=TIMESTEPS):\n",
        "    feats = batch.x.reshape(batch.x.shape[0], INPUT_DIM, -1)\n",
        "    # feats: n_nodes x dim x n_timesteps\n",
        "    assert(feats.shape[-1] >= 2*timesteps)\n",
        "\n",
        "    # For final evaluation, the encoder receives the 1st half of the trajectory.\n",
        "    feats_enc = feats[:,:,:timesteps]\n",
        "    # The decoder predicts the 2nd half of the trajectory.\n",
        "    feats_dec = feats[:,:,-timesteps:]\n",
        "    \n",
        "    feats_enc = torch.permute(feats_enc, [2,0,1]) \n",
        "    feats_dec = torch.permute(feats_dec, [2,0,1])[0,:,:].unsqueeze(0)\n",
        "    \n",
        "    # Encoder: predict the graph structure.\n",
        "    adj_matrix_logits = model_adj(feats_enc) \n",
        "    adj_matrix = gumbel_softmax(adj_matrix_logits, tau=1, hard=True)\n",
        "    adj_matrix_prob = my_softmax(adj_matrix_logits, -1) # n_nodes x n_nodes x 2\n",
        "\n",
        "    # Since we only have one type of edge, we can do this.\n",
        "    adj_matrix = adj_matrix[:,:,0]\n",
        "\n",
        "    # Decoder: use the predicted structure to predict the trajectory.\n",
        "    all_y_hat = []\n",
        "    for i in range(timesteps):\n",
        "      feats_dec  = model(feats_dec, adj_matrix)\n",
        "      all_y_hat.append(feats_dec)\n",
        "    \n",
        "    all_y_hat = torch.cat(all_y_hat, 0)\n",
        "    all_y_hat = all_y_hat.permute((1,2,0))\n",
        "\n",
        "    # n_nodes x dim x n_timesteps\n",
        "    return all_y_hat, batch.y[:,:,-timesteps:], adj_matrix_prob\n",
        "\n",
        "def train_epoch_nri_elbo(data_loader, model_adj, model, optimiser, epoch, loss_fct):\n",
        "    \"\"\" Train model for one epoch. \"\"\"\n",
        "    model.train()\n",
        "    num_iter = len(data_loader)\n",
        "\n",
        "    for i, batch in enumerate(data_loader):\n",
        "        batch = batch.to(DEVICE)\n",
        "        optimiser.zero_grad()\n",
        "        # During training we alwways use teacher forcing.\n",
        "        y_hat, y, adj_matrix_prob = forward_step_teacher_forcing_nri_elbo(batch, model_adj, model)\n",
        "        loss_rec = loss_fct(y_hat, y)\n",
        "        # TASK: compute the kl regularisation loss\n",
        "        # ============ YOUR CODE HERE  ============\n",
        "        # loss_kl = ..\n",
        "        # =========================================\n",
        "        loss = loss_rec + loss_kl\n",
        "\n",
        "        loss.backward()\n",
        "        optimiser.step()\n",
        "\n",
        "    return loss.data\n",
        "\n",
        "def eval_epoch_nri_elbo(data_loader, model_adj, model, loss_fct, forward_fct):\n",
        "    \"\"\" Evaluate model on dataset. \"\"\"\n",
        "    model.eval()\n",
        "    num_iter = len(data_loader)\n",
        "    loss_eval = 0\n",
        "\n",
        "    for i, batch in enumerate(data_loader):\n",
        "        # During evaluation we can switch between using the gt (teacher forcing)\n",
        "        # or the prediction as input for the next step.\n",
        "        batch = batch.to(DEVICE)\n",
        "        y_hat, y, _ = forward_fct(batch, model_adj, model)\n",
        "        loss = loss_fct(y_hat, y)\n",
        "        loss_eval += loss.data\n",
        "\n",
        "    loss_eval /= num_iter\n",
        "    return loss_eval\n",
        "\n",
        "def train_eval_loop_nri_elbo(model_adj, model, train_loader, val_loader, test_loader, \n",
        "               loss_fct, num_epochs=100,lr=0.0005):\n",
        "    \"\"\" Train the model for num_epochs epochs. \"\"\"\n",
        "    # Instantiate our optimiser.\n",
        "    optimiser = optim.Adam(list(model.parameters()) + list(model_adj.parameters()), lr=lr)\n",
        "    training_stats = None\n",
        "\n",
        "    # Initial evaluation (before training).\n",
        "    val_loss = eval_epoch_nri_elbo(val_loader,\n",
        "                                   model_adj,\n",
        "                                   model,\n",
        "                                   loss_fct,\n",
        "                                   forward_step_teacher_forcing_nri_elbo)\n",
        "    train_loss = eval_epoch_nri_elbo(train_loader,\n",
        "                                     model_adj,\n",
        "                                     model,\n",
        "                                     loss_fct,\n",
        "                                     forward_step_teacher_forcing_nri_elbo)\n",
        "    \n",
        "    epoch_stats = {\n",
        "        'train_loss': train_loss.cpu(), 'val_loss': val_loss.cpu(), 'epoch': 0\n",
        "    }\n",
        "    training_stats = update_stats(training_stats, epoch_stats)\n",
        "    print(f\"[Epoch 0]\",\n",
        "          f\"train loss: {train_loss:.5f} val loss: {val_loss:.5f}\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss  = train_epoch_nri_elbo(train_loader,\n",
        "                                           model_adj,\n",
        "                                           model,\n",
        "                                           optimiser,\n",
        "                                           epoch, \n",
        "                                           loss_fct)\n",
        "        \n",
        "        val_loss = eval_epoch_nri_elbo(val_loader,\n",
        "                                       model_adj,\n",
        "                                       model,\n",
        "                                       loss_fct,\n",
        "                                       forward_step_teacher_forcing_nri_elbo)\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "          print(f\"[Epoch {epoch+1}]\",\n",
        "                f\"train loss: {train_loss:.5f} val loss: {val_loss:.5f}\")\n",
        "        # store the loss and the computed metric for the final plot\n",
        "        epoch_stats = {\n",
        "            'train_loss': train_loss.cpu(), 'val_loss': val_loss.cpu(), 'epoch': epoch+1\n",
        "        }\n",
        "        training_stats = update_stats(training_stats, epoch_stats)\n",
        "    \n",
        "    test_loss_long_term = eval_epoch_nri_elbo(test_loader,\n",
        "                                              model_adj,\n",
        "                                              model,\n",
        "                                              loss_fct,\n",
        "                                              forward_step_pred_nri_elbo)\n",
        "\n",
        "    print(f\"Test metric long term: {test_loss_long_term:.3f}\")\n",
        "    return training_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEQcRDewzOhv"
      },
      "source": [
        "Let's train the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hySgSPMk-zzO"
      },
      "outputs": [],
      "source": [
        "nri_hidden_dim = 16#@param {type:\"integer\"}\n",
        "nri_num_layers = 2#@param {type:\"integer\"}\n",
        "LR = 0.0005#@param {type:\"number\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBCCZ142y6fb",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# TASK: Instantiate the MPNN Decoder (same as the one used before) and the MPNN Encoder. ; `adj_type` is\n",
        "# ignored since we are using the predicted one.\n",
        "# ============ YOUR CODE HERE  ============\n",
        "# model_nri_elbo = ..\n",
        "# model_adj_nri_elbo = ..\n",
        "# ===========================================\n",
        "model_nri_elbo = model_nri_elbo.to(DEVICE)\n",
        "model_adj_nri_elbo = model_adj_nri_elbo.to(DEVICE)\n",
        "                                        \n",
        "# Train the model\n",
        "train_stats = train_eval_loop_nri_elbo(model_adj_nri_elbo,\n",
        "                                       model_nri_elbo,\n",
        "                                       train_loader,\n",
        "                                       valid_loader,\n",
        "                                       test_loader,\n",
        "                                       loss_fct=F.mse_loss,\n",
        "                                       num_epochs=20,lr=LR)\n",
        "\n",
        "# Plot the training curve\n",
        "plot_stats(train_stats, name='MPNN_nri_elbo', figsize=(5, 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRMHMvkO9Qmp"
      },
      "source": [
        "## üî≠ Visualise the trajectories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTVCu-bL3dDD"
      },
      "outputs": [],
      "source": [
        "#@title Plot one of the trajectories\n",
        "example_index =  2#@param {type:\"integer\"}\n",
        "num_steps =  30#@param {type:\"integer\"}\n",
        "\n",
        "assert example_index >= 0 and example_index < len(test_dataset), \\\n",
        "    \"Need valid dataset index!\"\n",
        "\n",
        "test_sample= test_dataset[example_index].to(DEVICE)\n",
        "all_preds_tensor, all_targets_tensor, _ = forward_step_pred_nri_elbo(test_sample, model_adj_nri_elbo, model_nri_elbo)\n",
        "all_preds = all_preds_tensor.cpu().detach().numpy()\n",
        "\n",
        "all_targets = all_targets_tensor.cpu().detach().numpy()\n",
        "\n",
        "visualise_trajectory(all_preds, name=\"prediction\")\n",
        "visualise_trajectory(all_targets, name=\"ground-truth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPApyUVuzV07"
      },
      "source": [
        "## Additional resources (this is, of course, a non-exhaustive list!)\n",
        "\n",
        "1. Chaitanya Joshi's [blog post](https://graphdeeplearning.github.io/post/transformers-are-gnns/) on the link between GNNs and Transformers (2020).\n",
        "2. Xavier Bresson's [slide deck](https://www.dropbox.com/s/u82gcg3aath39hp/GNN_applications_Jun21.pdf?dl=0) on GNN applications (2021).\n",
        "3. Michael Bronstein's [TDS post](https://towardsdatascience.com/do-we-need-deep-graph-neural-networks-be62d3ec5c59) on whether we should 'stack more layers' in GNNs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sy8RLgPZzbEv"
      },
      "source": [
        "## Acknowledgements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TA_8CGEzcyo"
      },
      "source": [
        "We would like to thank [Thomas Kipf](https://tkipf.github.io/) for discussing the structure of this tutorial and for offering feedback and access to the original NRI codebase."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "[unsolved official]  EEML Graph Nets tutorial 13/07",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}